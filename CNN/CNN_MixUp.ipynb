{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cad52d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, default_collate\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.v2 import MixUp\n",
    "from snorkel.classification import cross_entropy_with_probs\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e1c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViolinViolaDataset(Dataset):\n",
    "    def __init__(self, root_dir, label_map = None, transform=None, ):\n",
    "        self.root_dir = root_dir\n",
    "        self.files = [f for f in os.listdir(root_dir) if f.endswith('.npy')]\n",
    "        self.label_map = label_map or {'violin': 0, 'viola': 1}\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.files[idx]\n",
    "        filepath = os.path.join(self.root_dir, filename)\n",
    "        mel = np.load(filepath)\n",
    "        spec = torch.from_numpy(mel)\n",
    "        spec = spec.unsqueeze(0)  # Add channel dimension\n",
    "        label = self.label_map[filename.split('_')[1]] if self.label_map else None\n",
    "        if self.transform:\n",
    "            spec = self.transform(spec)\n",
    "        return spec, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98da3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 517)),  # Resize to a fixed size\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalize the image\n",
    "])\n",
    "mixup = MixUp(num_classes=2, alpha=0.2)\n",
    "def mixup_fn(batch):\n",
    "    return mixup(*default_collate(batch))\n",
    "def one_hot_fn(batch, num_classes=2):\n",
    "    images, labels = default_collate(batch)\n",
    "    labels = F.one_hot(labels, num_classes=num_classes).float()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb2b57f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_train = torch.Generator()\n",
    "g_train.manual_seed(17)\n",
    "train_dataset = ViolinViolaDataset('train/', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=mixup_fn)\n",
    "\n",
    "g_testval = torch.Generator().manual_seed(17)\n",
    "testval_dataset = ViolinViolaDataset('test/', transform=transform)\n",
    "val_size = int(0.5 * len(testval_dataset))\n",
    "test_size = len(testval_dataset) - val_size\n",
    "val_subset, test_subset = random_split(testval_dataset, [val_size, test_size], generator=g_testval)\n",
    "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, collate_fn=one_hot_fn)\n",
    "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False, collate_fn=one_hot_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "598d62ad-04de-4fca-9678-20814e6a5d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After MixUp: images.shape = torch.Size([32, 1, 128, 517]), labels.shape = torch.Size([32, 2])\n",
      "tensor([0.2736, 0.7264])\n",
      "No MixUp: images.shape = torch.Size([32, 1, 128, 517]), labels.shape = torch.Size([32, 2])\n",
      "tensor([1., 0.])\n",
      "No MixUp: images.shape = torch.Size([32, 1, 128, 517]), labels.shape = torch.Size([32, 2])\n",
      "tensor([1., 0.])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(f\"After MixUp: {images.shape = }, {labels.shape = }\")\n",
    "    print(labels[31])\n",
    "    break\n",
    "for images, labels in val_loader:\n",
    "    print(f\"No MixUp: {images.shape = }, {labels.shape = }\")\n",
    "    print(labels[31])\n",
    "    break\n",
    "for images, labels in test_loader:\n",
    "    print(f\"No MixUp: {images.shape = }, {labels.shape = }\")\n",
    "    print(labels[31])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "826d05db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViolinViolaCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ViolinViolaCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=40, stride=(2, 1), kernel_size=(5, 1))   # output: (40, 62, 517)\n",
    "        self.dropout1 = nn.Dropout2d(p=0.35)\n",
    "        self.conv2 = nn.Conv2d(in_channels=40, out_channels=32, kernel_size=(3, 2))  # output: (32, 60, 516)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=1)  # output: (16, 60, 516)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((16, 16))  # reduce to fixed-size for Dense\n",
    "\n",
    "        self.fc1 = nn.Linear(16 * 16 * 16, 64)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.fc3 = nn.Linear(16, 12)\n",
    "        self.out = nn.Linear(12, 2)  # binary classification: violin vs viola\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # -> (40, 62, 517)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.conv2(x))  # -> (32, 60, 516)\n",
    "        x = F.relu(self.conv3(x))  # -> (16, 60, 516)\n",
    "        x = self.pool(x)           # -> (16, 16, 16)\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = F.relu(self.fc1(x))    # -> (64)\n",
    "        x = F.relu(self.fc2(x))    # -> (16)\n",
    "        x = F.relu(self.fc3(x))    # -> (12)\n",
    "        x = self.out(x)            # -> (2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1da4f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViolinViolaCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ViolinViolaCrossEntropyLoss, self).__init__()\n",
    "        self.register_buffer(\"class_weights\", torch.tensor([1.0, 1.2]))\n",
    "\n",
    "    def forward(self, outputs, labels):\n",
    "        if self.class_weights is not None:\n",
    "            class_weights = self.class_weights.to(outputs.device)\n",
    "            return cross_entropy_with_probs(outputs, labels, weight=class_weights)\n",
    "        return cross_entropy_with_probs(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5db427b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = ViolinViolaCNN()\n",
    "criterion = ViolinViolaCrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fa3d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    max_avg_acc = {}\n",
    "    model.to(device)\n",
    "\n",
    "    # Multi-GPU support\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs with DataParallel\")\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    else:\n",
    "        model.to(device)\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [], \"val_loss\": [],\n",
    "        \"train_acc\": [], \"val_acc\": [],\n",
    "        \"train_class_acc\": [], \"val_class_acc\": [],\n",
    "        \"train_class_loss\": [], \"val_class_loss\": [],\n",
    "        \"val_roc_y_true\": [], \"val_roc_y_score\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss, total_correct, total_samples = 0, 0, 0\n",
    "        class_loss = defaultdict(float)\n",
    "        class_correct = defaultdict(int)\n",
    "        class_total = defaultdict(int)\n",
    "\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_cls = y.argmax(dim=1)  # [B, 2] â†’ [B]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_loss += loss.item() * y.size(0)\n",
    "            total_correct += (preds == y_cls).sum().item()\n",
    "            total_samples += y.size(0)\n",
    "\n",
    "            for cls in [0, 1]:\n",
    "                idx = (y_cls == cls)\n",
    "                if idx.sum().item() > 0:\n",
    "                    cls_loss = criterion(logits[idx], y[idx])\n",
    "                    class_loss[cls] += cls_loss.item() * idx.sum().item()\n",
    "                    class_correct[cls] += (preds[idx] == y_cls[idx]).sum().item()\n",
    "                    class_total[cls] += idx.sum().item()\n",
    "\n",
    "        train_loss = total_loss / total_samples\n",
    "        train_acc = total_correct / total_samples\n",
    "        train_class_acc = [class_correct[c] / class_total[c] for c in [0, 1]]\n",
    "        train_class_loss = [class_loss[c] / class_total[c] for c in [0, 1]]\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"train_class_acc\"].append(train_class_acc)\n",
    "        history[\"train_class_loss\"].append(train_class_loss)\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        total_loss, total_correct, total_samples = 0, 0, 0\n",
    "        class_loss = defaultdict(float)\n",
    "        class_correct = defaultdict(int)\n",
    "        class_total = defaultdict(int)\n",
    "        val_y_true, val_y_score = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_cls = y.argmax(dim=1)  # convert [B, 2] to [B]\n",
    "\n",
    "                logits = model(X)\n",
    "                loss = criterion(logits, y)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                probs = torch.softmax(logits, dim=1)[:, 1]  # probability for class 1 (viola)\n",
    "\n",
    "                total_loss += loss.item() * y.size(0)\n",
    "                total_correct += (preds == y_cls).sum().item()\n",
    "                total_samples += y.size(0)\n",
    "\n",
    "                val_y_true.extend(y_cls.cpu().numpy())   # binary int labels for ROC\n",
    "                val_y_score.extend(probs.cpu().numpy())  # continuous scores\n",
    "\n",
    "                for cls in [0, 1]:\n",
    "                    idx = (y_cls == cls)\n",
    "                    if idx.sum().item() > 0:\n",
    "                        cls_loss = criterion(logits[idx], y[idx])\n",
    "                        class_loss[cls] += cls_loss.item() * idx.sum().item()\n",
    "                        class_correct[cls] += (preds[idx] == y_cls[idx]).sum().item()\n",
    "                        class_total[cls] += idx.sum().item()\n",
    "\n",
    "        val_loss = total_loss / total_samples\n",
    "        val_acc = total_correct / total_samples\n",
    "        val_class_acc = [class_correct[c] / class_total[c] for c in [0, 1]]\n",
    "        val_class_loss = [class_loss[c] / class_total[c] for c in [0, 1]]\n",
    "\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"val_class_acc\"].append(val_class_acc)\n",
    "        history[\"val_class_loss\"].append(val_class_loss)\n",
    "        history[\"val_roc_y_true\"] = val_y_true\n",
    "        history[\"val_roc_y_score\"] = val_y_score\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Violin Acc: {train_class_acc[0]:.4f} | Viola Acc: {train_class_acc[1]:.4f}\")\n",
    "        print(f\"  Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | Violin Acc: {val_class_acc[0]:.4f} | Viola Acc: {val_class_acc[1]:.4f}\")\n",
    "\n",
    "        # Save model every epoch\n",
    "        torch.save(model.state_dict(), f\"mixup/violin_viola_cnn_mixup_epoch_{epoch+1}.pth\")\n",
    "        print(f\"Model saved as mixup/violin_viola_cnn_mixup_epoch_{epoch+1}.pth\")\n",
    "        max_avg_acc[(epoch + 1)] = (train_acc + val_acc) / 2\n",
    "\n",
    "    return history, max_avg_acc\n",
    "\n",
    "def plot_history(history):\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss over Epochs\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
    "    plt.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy over Epochs\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc(y_true, y_score):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve (Violin vs Viola)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6d930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs with DataParallel\n",
      "Epoch 1/35\n",
      "  Train Loss: 0.6625 | Acc: 0.6826 | Violin Acc: 0.8493 | Viola Acc: 0.4242\n",
      "  Val   Loss: 0.5055 | Acc: 0.8021 | Violin Acc: 0.8682 | Viola Acc: 0.6625\n",
      "Model saved as mixup/violin_viola_cnn_mixup_epoch_1.pth\n",
      "Epoch 2/35\n",
      "  Train Loss: 0.4669 | Acc: 0.8231 | Violin Acc: 0.8441 | Viola Acc: 0.7905\n",
      "  Val   Loss: 0.4707 | Acc: 0.7910 | Violin Acc: 0.7719 | Viola Acc: 0.8313\n",
      "Model saved as mixup/violin_viola_cnn_mixup_epoch_2.pth\n",
      "Epoch 3/35\n",
      "  Train Loss: 0.4089 | Acc: 0.8564 | Violin Acc: 0.8652 | Viola Acc: 0.8428\n",
      "  Val   Loss: 0.4153 | Acc: 0.8300 | Violin Acc: 0.7997 | Viola Acc: 0.8940\n",
      "Model saved as mixup/violin_viola_cnn_mixup_epoch_3.pth\n"
     ]
    }
   ],
   "source": [
    "history, max_avg_acc = train(model, train_loader, val_loader, criterion, optimizer, device='cuda', num_epochs=35)\n",
    "\n",
    "plot_history(history)\n",
    "plot_roc(history[\"val_roc_y_true\"], history[\"val_roc_y_score\"])\n",
    "\n",
    "# Restore the best model based on maximum average accuracy\n",
    "best_epoch = max(max_avg_acc, key=max_avg_acc.get)\n",
    "state_dict = torch.load(f\"mixup/violin_viola_cnn_mixup_epoch_{best_epoch}.pth\")\n",
    "# Remove 'module.' prefix from all keys\n",
    "new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "print(f\"Best model restored from epoch {best_epoch} with max average accuracy {max_avg_acc[best_epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e023c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test Accuracy: 0.7880\n",
      "  Class 0 Accuracy: 0.8579\n",
      "  Class 1 Accuracy: 0.6461\n",
      "Average Class Accuracy: 0.7520\n",
      "F1 Score (macro): 0.7561\n",
      "Precision (macro): 0.7612\n",
      "Recall (macro): 0.7520\n",
      "----------------------------------------\n",
      "Epoch 2: Test Accuracy: 0.7840\n",
      "  Class 0 Accuracy: 0.7611\n",
      "  Class 1 Accuracy: 0.8306\n",
      "Average Class Accuracy: 0.7958\n",
      "F1 Score (macro): 0.7713\n",
      "Precision (macro): 0.7663\n",
      "Recall (macro): 0.7958\n",
      "----------------------------------------\n",
      "Epoch 3: Test Accuracy: 0.8201\n",
      "  Class 0 Accuracy: 0.7886\n",
      "  Class 1 Accuracy: 0.8840\n",
      "Average Class Accuracy: 0.8363\n",
      "F1 Score (macro): 0.8094\n",
      "Precision (macro): 0.8028\n",
      "Recall (macro): 0.8363\n",
      "----------------------------------------\n",
      "Epoch 4: Test Accuracy: 0.8618\n",
      "  Class 0 Accuracy: 0.8616\n",
      "  Class 1 Accuracy: 0.8622\n",
      "Average Class Accuracy: 0.8619\n",
      "F1 Score (macro): 0.8489\n",
      "Precision (macro): 0.8406\n",
      "Recall (macro): 0.8619\n",
      "----------------------------------------\n",
      "Epoch 5: Test Accuracy: 0.8961\n",
      "  Class 0 Accuracy: 0.9088\n",
      "  Class 1 Accuracy: 0.8705\n",
      "Average Class Accuracy: 0.8896\n",
      "F1 Score (macro): 0.8841\n",
      "Precision (macro): 0.8795\n",
      "Recall (macro): 0.8896\n",
      "----------------------------------------\n",
      "Epoch 6: Test Accuracy: 0.8984\n",
      "  Class 0 Accuracy: 0.8754\n",
      "  Class 1 Accuracy: 0.9450\n",
      "Average Class Accuracy: 0.9102\n",
      "F1 Score (macro): 0.8901\n",
      "Precision (macro): 0.8794\n",
      "Recall (macro): 0.9102\n",
      "----------------------------------------\n",
      "Epoch 7: Test Accuracy: 0.9279\n",
      "  Class 0 Accuracy: 0.9318\n",
      "  Class 1 Accuracy: 0.9202\n",
      "Average Class Accuracy: 0.9260\n",
      "F1 Score (macro): 0.9197\n",
      "Precision (macro): 0.9143\n",
      "Recall (macro): 0.9260\n",
      "----------------------------------------\n",
      "Epoch 8: Test Accuracy: 0.9230\n",
      "  Class 0 Accuracy: 0.9277\n",
      "  Class 1 Accuracy: 0.9134\n",
      "Average Class Accuracy: 0.9205\n",
      "F1 Score (macro): 0.9142\n",
      "Precision (macro): 0.9088\n",
      "Recall (macro): 0.9205\n",
      "----------------------------------------\n",
      "Epoch 9: Test Accuracy: 0.9212\n",
      "  Class 0 Accuracy: 0.9047\n",
      "  Class 1 Accuracy: 0.9548\n",
      "Average Class Accuracy: 0.9297\n",
      "F1 Score (macro): 0.9139\n",
      "Precision (macro): 0.9037\n",
      "Recall (macro): 0.9297\n",
      "----------------------------------------\n",
      "Epoch 10: Test Accuracy: 0.9180\n",
      "  Class 0 Accuracy: 0.9106\n",
      "  Class 1 Accuracy: 0.9330\n",
      "Average Class Accuracy: 0.9218\n",
      "F1 Score (macro): 0.9098\n",
      "Precision (macro): 0.9011\n",
      "Recall (macro): 0.9218\n",
      "----------------------------------------\n",
      "Epoch 11: Test Accuracy: 0.9267\n",
      "  Class 0 Accuracy: 0.9299\n",
      "  Class 1 Accuracy: 0.9202\n",
      "Average Class Accuracy: 0.9250\n",
      "F1 Score (macro): 0.9184\n",
      "Precision (macro): 0.9127\n",
      "Recall (macro): 0.9250\n",
      "----------------------------------------\n",
      "Epoch 12: Test Accuracy: 0.9269\n",
      "  Class 0 Accuracy: 0.9588\n",
      "  Class 1 Accuracy: 0.8622\n",
      "Average Class Accuracy: 0.9105\n",
      "F1 Score (macro): 0.9162\n",
      "Precision (macro): 0.9228\n",
      "Recall (macro): 0.9105\n",
      "----------------------------------------\n",
      "Epoch 13: Test Accuracy: 0.9344\n",
      "  Class 0 Accuracy: 0.9674\n",
      "  Class 1 Accuracy: 0.8675\n",
      "Average Class Accuracy: 0.9174\n",
      "F1 Score (macro): 0.9245\n",
      "Precision (macro): 0.9329\n",
      "Recall (macro): 0.9174\n",
      "----------------------------------------\n",
      "Epoch 14: Test Accuracy: 0.9386\n",
      "  Class 0 Accuracy: 0.9466\n",
      "  Class 1 Accuracy: 0.9224\n",
      "Average Class Accuracy: 0.9345\n",
      "F1 Score (macro): 0.9311\n",
      "Precision (macro): 0.9280\n",
      "Recall (macro): 0.9345\n",
      "----------------------------------------\n",
      "Epoch 15: Test Accuracy: 0.9287\n",
      "  Class 0 Accuracy: 0.9429\n",
      "  Class 1 Accuracy: 0.8998\n",
      "Average Class Accuracy: 0.9214\n",
      "F1 Score (macro): 0.9197\n",
      "Precision (macro): 0.9181\n",
      "Recall (macro): 0.9214\n",
      "----------------------------------------\n",
      "Epoch 16: Test Accuracy: 0.9088\n",
      "  Class 0 Accuracy: 0.8850\n",
      "  Class 1 Accuracy: 0.9571\n",
      "Average Class Accuracy: 0.9210\n",
      "F1 Score (macro): 0.9012\n",
      "Precision (macro): 0.8903\n",
      "Recall (macro): 0.9210\n",
      "----------------------------------------\n",
      "Epoch 17: Test Accuracy: 0.9292\n",
      "  Class 0 Accuracy: 0.9737\n",
      "  Class 1 Accuracy: 0.8389\n",
      "Average Class Accuracy: 0.9063\n",
      "F1 Score (macro): 0.9175\n",
      "Precision (macro): 0.9324\n",
      "Recall (macro): 0.9063\n",
      "----------------------------------------\n",
      "Epoch 18: Test Accuracy: 0.9230\n",
      "  Class 0 Accuracy: 0.9599\n",
      "  Class 1 Accuracy: 0.8479\n",
      "Average Class Accuracy: 0.9039\n",
      "F1 Score (macro): 0.9112\n",
      "Precision (macro): 0.9200\n",
      "Recall (macro): 0.9039\n",
      "----------------------------------------\n",
      "Epoch 19: Test Accuracy: 0.9108\n",
      "  Class 0 Accuracy: 0.8935\n",
      "  Class 1 Accuracy: 0.9458\n",
      "Average Class Accuracy: 0.9197\n",
      "F1 Score (macro): 0.9028\n",
      "Precision (macro): 0.8925\n",
      "Recall (macro): 0.9197\n",
      "----------------------------------------\n",
      "Epoch 20: Test Accuracy: 0.9384\n",
      "  Class 0 Accuracy: 0.9488\n",
      "  Class 1 Accuracy: 0.9172\n",
      "Average Class Accuracy: 0.9330\n",
      "F1 Score (macro): 0.9307\n",
      "Precision (macro): 0.9285\n",
      "Recall (macro): 0.9330\n",
      "----------------------------------------\n",
      "Epoch 21: Test Accuracy: 0.9364\n",
      "  Class 0 Accuracy: 0.9751\n",
      "  Class 1 Accuracy: 0.8577\n",
      "Average Class Accuracy: 0.9164\n",
      "F1 Score (macro): 0.9263\n",
      "Precision (macro): 0.9387\n",
      "Recall (macro): 0.9164\n",
      "----------------------------------------\n",
      "Epoch 22: Test Accuracy: 0.9264\n",
      "  Class 0 Accuracy: 0.9733\n",
      "  Class 1 Accuracy: 0.8313\n",
      "Average Class Accuracy: 0.9023\n",
      "F1 Score (macro): 0.9142\n",
      "Precision (macro): 0.9301\n",
      "Recall (macro): 0.9023\n",
      "----------------------------------------\n",
      "Epoch 23: Test Accuracy: 0.9264\n",
      "  Class 0 Accuracy: 0.9232\n",
      "  Class 1 Accuracy: 0.9330\n",
      "Average Class Accuracy: 0.9281\n",
      "F1 Score (macro): 0.9186\n",
      "Precision (macro): 0.9112\n",
      "Recall (macro): 0.9281\n",
      "----------------------------------------\n",
      "Epoch 24: Test Accuracy: 0.9172\n",
      "  Class 0 Accuracy: 0.9188\n",
      "  Class 1 Accuracy: 0.9142\n",
      "Average Class Accuracy: 0.9165\n",
      "F1 Score (macro): 0.9082\n",
      "Precision (macro): 0.9016\n",
      "Recall (macro): 0.9165\n",
      "----------------------------------------\n",
      "Epoch 25: Test Accuracy: 0.9346\n",
      "  Class 0 Accuracy: 0.9692\n",
      "  Class 1 Accuracy: 0.8645\n",
      "Average Class Accuracy: 0.9168\n",
      "F1 Score (macro): 0.9247\n",
      "Precision (macro): 0.9341\n",
      "Recall (macro): 0.9168\n",
      "----------------------------------------\n",
      "Epoch 26: Test Accuracy: 0.9192\n",
      "  Class 0 Accuracy: 0.9191\n",
      "  Class 1 Accuracy: 0.9194\n",
      "Average Class Accuracy: 0.9193\n",
      "F1 Score (macro): 0.9105\n",
      "Precision (macro): 0.9036\n",
      "Recall (macro): 0.9193\n",
      "----------------------------------------\n",
      "Epoch 27: Test Accuracy: 0.9332\n",
      "  Class 0 Accuracy: 0.9662\n",
      "  Class 1 Accuracy: 0.8660\n",
      "Average Class Accuracy: 0.9161\n",
      "F1 Score (macro): 0.9231\n",
      "Precision (macro): 0.9314\n",
      "Recall (macro): 0.9161\n",
      "----------------------------------------\n",
      "Epoch 28: Test Accuracy: 0.9252\n",
      "  Class 0 Accuracy: 0.9696\n",
      "  Class 1 Accuracy: 0.8351\n",
      "Average Class Accuracy: 0.9023\n",
      "F1 Score (macro): 0.9130\n",
      "Precision (macro): 0.9269\n",
      "Recall (macro): 0.9023\n",
      "----------------------------------------\n",
      "Epoch 29: Test Accuracy: 0.9346\n",
      "  Class 0 Accuracy: 0.9470\n",
      "  Class 1 Accuracy: 0.9096\n",
      "Average Class Accuracy: 0.9283\n",
      "F1 Score (macro): 0.9264\n",
      "Precision (macro): 0.9246\n",
      "Recall (macro): 0.9283\n",
      "----------------------------------------\n",
      "Epoch 30: Test Accuracy: 0.9138\n",
      "  Class 0 Accuracy: 0.8921\n",
      "  Class 1 Accuracy: 0.9578\n",
      "Average Class Accuracy: 0.9249\n",
      "F1 Score (macro): 0.9063\n",
      "Precision (macro): 0.8955\n",
      "Recall (macro): 0.9249\n",
      "----------------------------------------\n",
      "Epoch 31: Test Accuracy: 0.9222\n",
      "  Class 0 Accuracy: 0.9225\n",
      "  Class 1 Accuracy: 0.9217\n",
      "Average Class Accuracy: 0.9221\n",
      "F1 Score (macro): 0.9137\n",
      "Precision (macro): 0.9070\n",
      "Recall (macro): 0.9221\n",
      "----------------------------------------\n",
      "Epoch 32: Test Accuracy: 0.9105\n",
      "  Class 0 Accuracy: 0.8913\n",
      "  Class 1 Accuracy: 0.9495\n",
      "Average Class Accuracy: 0.9204\n",
      "F1 Score (macro): 0.9027\n",
      "Precision (macro): 0.8922\n",
      "Recall (macro): 0.9204\n",
      "----------------------------------------\n",
      "Epoch 33: Test Accuracy: 0.9232\n",
      "  Class 0 Accuracy: 0.9262\n",
      "  Class 1 Accuracy: 0.9172\n",
      "Average Class Accuracy: 0.9217\n",
      "F1 Score (macro): 0.9146\n",
      "Precision (macro): 0.9087\n",
      "Recall (macro): 0.9217\n",
      "----------------------------------------\n",
      "Epoch 34: Test Accuracy: 0.9423\n",
      "  Class 0 Accuracy: 0.9455\n",
      "  Class 1 Accuracy: 0.9360\n",
      "Average Class Accuracy: 0.9407\n",
      "F1 Score (macro): 0.9356\n",
      "Precision (macro): 0.9310\n",
      "Recall (macro): 0.9407\n",
      "----------------------------------------\n",
      "Epoch 35: Test Accuracy: 0.9374\n",
      "  Class 0 Accuracy: 0.9670\n",
      "  Class 1 Accuracy: 0.8773\n",
      "Average Class Accuracy: 0.9221\n",
      "F1 Score (macro): 0.9281\n",
      "Precision (macro): 0.9351\n",
      "Recall (macro): 0.9221\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "for epoch in range(1, 36):\n",
    "    state_dict = torch.load(f\"mixup/violin_viola_cnn_mixup_epoch_{epoch}.pth\")\n",
    "    new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.to('cpu')\n",
    "    model.eval()\n",
    "\n",
    "    total_correct, total_samples = 0, 0\n",
    "    class_correct = defaultdict(int)\n",
    "    class_total = defaultdict(int)\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to('cpu'), y.to('cpu')  # y is one-hot, shape [B, 2]\n",
    "            y_cls = y.argmax(dim=1)         # convert to shape [B]\n",
    "\n",
    "            logits = model(X)\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            total_correct += (preds == y_cls).sum().item()\n",
    "            total_samples += y_cls.size(0)\n",
    "\n",
    "            # For accuracy\n",
    "            for i in range(y_cls.size(0)):\n",
    "                label = y_cls[i].item()\n",
    "                class_total[label] += 1\n",
    "                class_correct[label] += (preds[i].item() == label)\n",
    "\n",
    "            # For F1/Precision/Recall\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_labels.extend(y_cls.tolist())\n",
    "\n",
    "    test_acc = total_correct / total_samples\n",
    "    print(f\"Epoch {epoch}: Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    for cls in [0, 1]:\n",
    "        if class_total[cls] > 0:\n",
    "            class_acc = class_correct[cls] / class_total[cls]\n",
    "            print(f\"  Class {cls} Accuracy: {class_acc:.4f}\")\n",
    "\n",
    "    avg_class_acc = sum(class_correct[c] / class_total[c] for c in [0, 1]) / 2\n",
    "    print(f\"Average Class Accuracy: {avg_class_acc:.4f}\")\n",
    "\n",
    "    # F1, Precision, Recall (macro = average across classes)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    print(f\"F1 Score (macro): {f1:.4f}\")\n",
    "    print(f\"Precision (macro): {precision:.4f}\")\n",
    "    print(f\"Recall (macro): {recall:.4f}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a775f37-2df8-4164-b3d0-b34869ef8601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best choice: Epoch 34"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
